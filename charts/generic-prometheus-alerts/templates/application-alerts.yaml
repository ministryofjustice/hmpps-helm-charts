{{- $targetNamespace := .Release.Namespace }}
{{- $targetApplication := required "A value for targetApplication must be set" .Values.targetApplication }}
{{- $targetApplicationRegex := printf "%s.*" .Values.targetApplication }}
{{- $targetPod := default $targetApplicationRegex .Values.podTargetOverride }}
{{- $targetDeployment := default .Values.targetApplication .Values.deploymentTargetOverride }}
{{- $targetJobName := default $targetApplicationRegex .Values.jobTargetOverride }}
{{- $targetCronjob := default $targetApplicationRegex .Values.cronjobTargetOverride }}
{{- $targetHpa := default .Values.targetApplication .Values.hpaTargetOverride }}
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: {{ $targetApplication }}-app
  labels:
    {{- include "generic-prometheus-alerts.labels" . | nindent 4 }}
spec:
  groups:
    - name: {{ $targetApplication }}-app
      rules:
        - alert: KubePodCrashLooping
          annotations:
            message: Pod {{`{{`}} $labels.namespace {{`}}`}}/{{`{{`}} $labels.pod {{`}}`}} ({{`{{`}} $labels.container {{`}}`}}) is restarting {{`{{`}} printf "%.2f" $value {{`}}`}} times / 5 minutes.
            runbook_url: {{ .Values.runbookUrl }}alert-name-kubepodcrashlooping
            summary: Pod is crash looping.
          expr: |
            rate(kube_pod_container_status_restarts_total{job="kube-state-metrics", namespace=~"{{ $targetNamespace }}", pod=~"{{ $targetPod }}"}[10m]) * 60 * 5 > 0
          for: 15m
          labels:
            severity: {{ .Values.alertSeverity }}
        - alert: KubePodNotReady
          annotations:
            message: Pod {{`{{`}} $labels.namespace {{`}}`}}/{{`{{`}} $labels.pod {{`}}`}} has been in a non-ready state for longer than 15 minutes.
            runbook_url: {{ .Values.runbookUrl }}alert-name-kubepodnotready
            summary: Pod has been in a non-ready state for more than 15 minutes.
          expr: sum by (namespace, pod) (kube_pod_status_phase{job="kube-state-metrics", namespace=~"{{ $targetNamespace }}", pod=~"{{ $targetPod }}", phase=~"Pending|Unknown"}) > 0
          for: 15m
          labels:
            severity: {{ .Values.alertSeverity }}
        - alert: KubeDeploymentGenerationMismatch
          annotations:
            message: Deployment generation for {{`{{`}} $labels.namespace {{`}}`}}/{{`{{`}} $labels.deployment {{`}}`}} does not match, this indicates that the Deployment has failed but has not been rolled back.
            runbook_url: {{ .Values.runbookUrl }}alert-name-kubedeploymentgenerationmismatch
            summary: Deployment generation mismatch due to possible roll-back
          expr: |-
            kube_deployment_status_observed_generation{job="kube-state-metrics", namespace=~"{{ $targetNamespace }}", deployment=~"{{ $targetDeployment }}"}
              !=
            kube_deployment_metadata_generation{job="kube-state-metrics", namespace=~"{{ $targetNamespace }}", deployment=~"{{ $targetDeployment }}"}
          for: 15m
          labels:
            severity: {{ .Values.alertSeverity }}
        - alert: KubeDeploymentReplicasMismatch
          annotations:
            message: Deployment {{`{{`}} $labels.namespace {{`}}`}}/{{`{{`}} $labels.deployment {{`}}`}} has not matched the expected number of replicas for longer 15 minutes.
            runbook_url: {{ .Values.runbookUrl }}alert-name-kubedeploymentreplicasmismatch
            summary: Deployment has not matched the expected number of replicas.
          expr: |-
            kube_deployment_spec_replicas{job="kube-state-metrics", namespace=~"{{ $targetNamespace }}", deployment=~"{{ $targetDeployment }}"}
              !=
            kube_deployment_status_replicas_available{job="kube-state-metrics", namespace=~"{{ $targetNamespace }}", deployment=~"{{ $targetDeployment }}"}
          for: 15m
          labels:
            severity: {{ .Values.alertSeverity }}
        - alert: KubeContainerWaiting
          annotations:
            description: Pod {{`{{`}} $labels.namespace {{`}}`}}/{{`{{`}} $labels.pod {{`}}`}} container {{`{{`}} $labels.container {{`}}`}} has been in waiting state for longer than 1 hour.
            runbook_url: {{ .Values.runbookUrl }}kubecontainerwaiting
            summary: Pod container waiting longer than 1 hour
          expr: |
            sum by (namespace, pod, container) (kube_pod_container_status_waiting_reason{job="kube-state-metrics", namespace=~"{{ $targetNamespace }}", pod=~"{{ $targetPod }}"}) > 0
          for: 1h
          labels:
            severity: {{ .Values.alertSeverity }}
        - alert: KubeCronJobRunning
          annotations:
            message: CronJob {{`{{`}} $labels.namespace {{`}}`}}/{{`{{`}} $labels.cronjob {{`}}`}} is taking more than 1h to complete.
            runbook_url: {{ .Values.runbookUrl }}alert-name-kubecronjobrunning
            summary: CronJob taking a long time to complete.
          expr: time() - kube_cronjob_next_schedule_time{job="kube-state-metrics", namespace=~"{{ $targetNamespace }}", cronjob=~"{{ $targetCronjob }}"} > 3600
          for: 1h
          labels:
            severity: {{ .Values.alertSeverity }}
        - alert: KubeJobCompletion
          annotations:
            message: Job {{`{{`}} $labels.namespace {{`}}`}}/{{`{{`}} $labels.job_name {{`}}`}} is taking more than six hour to complete.
            runbook_url: {{ .Values.runbookUrl }}alert-name-kubejobcompletion
          expr: |
            kube_job_spec_completions{job="kube-state-metrics", namespace=~"{{ $targetNamespace }}", job_name=~"{{ $targetJobName }}"}
            - kube_job_status_succeeded{job="kube-state-metrics", namespace=~"{{ $targetNamespace }}", job_name=~"{{ $targetJobName }}"} > 0
          for: 6h
          labels:
            severity: {{ .Values.alertSeverity }}
        - alert: KubeJobFailed
          annotations:
            message: Job {{`{{`}} $labels.namespace {{`}}`}}/{{`{{`}} $labels.job_name {{`}}`}} failed to complete.
            runbook_url: {{ .Values.runbookUrl }}alert-name-kubejobfailed
            summary: Job failed to complete.
          expr: kube_job_status_failed{job="kube-state-metrics", namespace=~"{{ $targetNamespace }}", job_name=~"{{ $targetJobName }}"} > 0
          for: 15m
          labels:
            severity: {{ .Values.alertSeverity }}
        - alert: KubeHpaReplicasMismatch
          annotations:
            description: HPA {{`{{`}} $labels.namespace {{`}}`}}/{{`{{`}} $labels.hpa {{`}}`}} has not matched the desired number of replicas for longer than 15 minutes.
            runbook_url: {{ .Values.runbookUrl }}kubehpareplicasmismatch
            summary: HPA has not matched desired number of replicas.
          expr: |
            (kube_hpa_status_desired_replicas{job="kube-state-metrics", namespace=~"{{ $targetNamespace }}", hpa=~"{{ $targetHpa }}"}
              !=
            kube_hpa_status_current_replicas{job="kube-state-metrics"})
              and
            (kube_hpa_status_current_replicas{job="kube-state-metrics"}
              >
            kube_hpa_spec_min_replicas{job="kube-state-metrics"})
              and
            (kube_hpa_status_current_replicas{job="kube-state-metrics"}
              <
            kube_hpa_spec_max_replicas{job="kube-state-metrics"})
              and
            changes(kube_hpa_status_current_replicas{job="kube-state-metrics"}[15m]) == 0
          for: 15m
          labels:
            severity: {{ .Values.alertSeverity }}
        - alert: KubeHpaMaxedOut
          annotations:
            description: HPA {{`{{`}} $labels.namespace {{`}}`}}/{{`{{`}} $labels.hpa {{`}}`}} has been running at max replicas for longer than 15 minutes.
            runbook_url: {{ .Values.runbookUrl }}kubehpamaxedout
            summary: HPA is running at max replicas
          expr: |
            kube_hpa_status_current_replicas{job="kube-state-metrics", namespace=~"{{ $targetNamespace }}", hpa=~"{{ $targetHpa }}"}
              ==
            kube_hpa_spec_max_replicas{job="kube-state-metrics"}
          for: 15m
          labels:
            severity: {{ .Values.alertSeverity }}
        - alert: KubeQuotaExceeded
          annotations:
            message: Namespace {{`{{`}} $labels.namespace {{`}}`}} is using {{`{{`}} printf "%0.0f" $value {{`}}`}}% of its {{`{{`}} $labels.resource {{`}}`}} quota.
            runbook_url: {{ .Values.runbookUrl }}KubeQuotaExceeded
            summary: Namespace quota has exceeded the limits.
          expr: |-
            100 * kube_resourcequota{namespace=~"{{ $targetNamespace }}", job="kube-state-metrics", type="used"}
              / ignoring(instance, job, type)
            (kube_resourcequota{namespace=~"{{ $targetNamespace }}", job="kube-state-metrics", type="hard"} > 0)
              > 90
          for: 15m
          labels:
            severity: {{ .Values.alertSeverity }}
        - alert: KubeContainerOOMKilled
          annotations:
            message: "Container {{`{{`}} $labels.container {{`}}`}} in pod {{`{{`}} $labels.namespace {{`}}`}}/{{`{{`}} $labels.pod {{`}}`}} has been OOM Killed (out of memory) {{`{{`}} $value {{`}}`}} times in the last 10 minutes."
            runbook_url: {{ .Values.runbookUrl }}KubeContainerOOMKilled
            summary: Kubernetes container OOM killed (instance {{`{{`}} $labels.instance {{`}}`}})
          expr: |-
            (kube_pod_container_status_restarts_total{job="kube-state-metrics", namespace=~"{{ $targetNamespace }}", pod=~"{{ $targetPod }}"}
             - kube_pod_container_status_restarts_total{job="kube-state-metrics", namespace=~"{{ $targetNamespace }}", pod=~"{{ $targetPod }}"} offset 10m >= 1)
              and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{job="kube-state-metrics", namespace=~"{{ $targetNamespace }}", pod=~"{{ $targetPod }}", reason="OOMKilled"}[10m]) == 1
          for: 0m
          labels:
            severity: {{ .Values.alertSeverity }}
