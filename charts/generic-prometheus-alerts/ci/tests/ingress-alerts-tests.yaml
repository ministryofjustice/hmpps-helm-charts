---
rule_files:
  - ../test-application-ingress.yaml
  - ../test-business-hours-ingress.yaml

evaluation_interval: 1m

tests:
  - interval: 1m
    input_series:
      - series: 'nginx_ingress_controller_requests{exported_namespace="test-application-dev", ingress="test-application-ingress", path="/", status="500"}'
        values: '0 1 3'
      - series: 'nginx_ingress_controller_requests{exported_namespace="test-application-dev", ingress="test-application-ingress", path="/", status="501"}'
        values: '0 2 5'

    name: 5xxErrorResponses alert fired as request rate increases over the duration of the 1 minute time range window

    # this is here to help folks better understand the promql expression
    # assert that
    #   at 2m the rate (increase per second) in the last minute: for 500 requests it's 0.03 ((3 - 1) / 60), for 501 requests it's 0.05 ((5 - 2) / 60)
    #   which is greater than 0
    #   the average of those is 0.041
    promql_expr_test:
      - expr: avg(rate(nginx_ingress_controller_requests{exported_namespace="test-application-dev", ingress="test-application-ingress", path="/", status=~"5.*"}[1m]) > 0) by (ingress, exported_namespace)
        eval_time: 2m
        exp_samples:
          - labels: '{exported_namespace="test-application-dev", ingress="test-application-ingress"}'
            value: 0.04166666666666667

    alert_rule_test:
      # assert that the 5xx alert is firing
      - eval_time: 2m
        alertname: 5xxErrorResponses
        exp_alerts:
          - exp_labels:
              alertname: 5xxErrorResponses
              exported_namespace: test-application-dev
              ingress: test-application-ingress
              severity: alert-severity-tag
            exp_annotations:
              message: "Ingress test-application-dev/test-application-ingress is serving 5xx responses."
              runbook_url: https://runbook.com/ingress-5xx-error-responses
              dashboard_url: https://grafana.live.cloud-platform.service.justice.gov.uk/d/golden-signals/golden-signals?orgId=1&var-namespace=test-application-dev&var-service=test-application

  - interval: 1m
    input_series:
      - series: 'nginx_ingress_controller_requests{exported_namespace="test-business-hours-dev", ingress="test-business-hours-ingress", status="500"}'
        values: '0 1 3'
      - series: 'nginx_ingress_controller_requests{exported_namespace="test-business-hours-dev", ingress="test-business-hours-ingress", status="501"}'
        values: '0 2 5'

    name: 5xxErrorResponses alert doesn't fire outside of business hours

    promql_expr_test:
      - expr: avg(rate(nginx_ingress_controller_requests{exported_namespace="test-business-hours-dev", ingress="test-business-hours-ingress", status=~"5.*"}[1m]) > 0) by (ingress, exported_namespace)
        eval_time: 2m
        exp_samples:
          - labels: '{exported_namespace="test-business-hours-dev", ingress="test-business-hours-ingress"}'
            value: 0.04166666666666667

    alert_rule_test:
      # assert that the 5xx alert is not firing as outside of business hours
      - eval_time: 2m
        alertname: 5xxErrorResponses
        exp_alerts: []

  - interval: 1m
    input_series:
      - series: 'nginx_ingress_controller_requests{exported_namespace="test-application-dev", ingress="test-application-ingress", status="500"}'
        values: '0 1 0'

    name: 5xxErrorResponses alert not fired as request rate decreases over the duration of the 1 minute time range window

    # this is here to help folks better understand the promql expression
    # at 2m the rate (increase per second) in the last minute: 0 which is not greater than 0, assert nothing is returned
    promql_expr_test:
      - expr: avg(rate(nginx_ingress_controller_requests{exported_namespace="test-application-dev", ingress="test-application-ingress", status=~"5.*"}[1m]) > 0) by (ingress, exported_namespace)
        eval_time: 2m
        exp_samples: []

    alert_rule_test:
      # assert that the 5xx alert is NOT firing
      - eval_time: 2m
        alertname: 5xxErrorResponses
        exp_alerts: []

  ## alert:
  ##   - RatelimitBlocking
  ##
  - interval: 1m
    input_series:
      - series: 'nginx_ingress_controller_requests{exported_namespace="test-application-dev", ingress="test-application-ingress", status="429"}'
        values: '0 1 3'

    name: RatelimitBlocking alert fired as request rate increases over the duration of the 1 minute time range window

    # this is here to help folks better understand the promql expression
    # assert that
    #   at 2m the rate (increase per second) in the last minute: 0.03 ((3 - 1) / 60)
    #   which is greater than 0
    #   the average is 0.03
    promql_expr_test:
      - expr: avg(rate(nginx_ingress_controller_requests{exported_namespace="test-application-dev", ingress="test-application-ingress", status=~"429"}[1m]) > 0) by (ingress, exported_namespace)
        eval_time: 2m
        exp_samples:
          - labels: '{exported_namespace="test-application-dev", ingress="test-application-ingress"}'
            value: 0.03333333333333333

    alert_rule_test:
      # assert that the RatelimitBlocking alert is firing
      - eval_time: 2m
        alertname: RatelimitBlocking
        exp_alerts:
          - exp_labels:
              alertname: RatelimitBlocking
              exported_namespace: test-application-dev
              ingress: test-application-ingress
              severity: alert-severity-tag
            exp_annotations:
              message: "Rate limit is being applied on ingress test-application-dev/test-application-ingress."
              runbook_url: https://runbook.com/ingress-rate-limiting
              dashboard_url: https://grafana.live.cloud-platform.service.justice.gov.uk/d/golden-signals/golden-signals?orgId=1&var-namespace=test-application-dev&var-service=test-application

  - interval: 1m
    input_series:
      - series: 'nginx_ingress_controller_requests{exported_namespace="test-application-dev", ingress="test-application-ingress", status="429"}'
        values: '0 1 0'

    name: RatelimitBlocking alert not fired as request rate decreases over the duration of the 1 minute time range window

    # this is here to help folks better understand the promql expression
    # at 2m the rate (increase per second) in the last minute: 0 which is not greater than 0, assert nothing is returned
    promql_expr_test:
      - expr: avg(rate(nginx_ingress_controller_requests{exported_namespace="test-application-dev", ingress="test-application-ingress", status=~"429"}[1m]) > 0) by (ingress, exported_namespace)
        eval_time: 2m
        exp_samples: []

    alert_rule_test:
      # assert that the RatelimitBlocking alert is NOT firing
      - eval_time: 2m
        alertname: RatelimitBlocking
        exp_alerts: []

  ## alert:
  ##   - ModSecurityBlocking
  ##
  - interval: 1m
    input_series:
      - series: 'nginx_ingress_controller_requests{exported_namespace="test-application-dev", ingress="test-application-ingress", status="406"}'
        values: '0 21 43'

    name: ModSecurityBlocking alert fired as request rate is greater than 20 over the duration of the 1 minute time range window

    # this is here to help folks better understand the promql expression
    # assert that
    #   at 2m the rate (increase per second) in the last minute: 0.35 ((43 - 21) / 60)
    #   which is greater than 0.33
    #   the average is 0.36
    promql_expr_test:
      - expr: avg(rate(nginx_ingress_controller_requests{exported_namespace="test-application-dev", ingress="test-application-ingress", status=~"406"}[1m]) > 0.33) by (ingress, exported_namespace)
        eval_time: 2m
        exp_samples:
          - labels: '{exported_namespace="test-application-dev", ingress="test-application-ingress"}'
            value: 0.36666666666666664

    alert_rule_test:
      # assert that the ModSecurityBlocking alert is firing
      - eval_time: 2m
        alertname: ModSecurityBlocking
        exp_alerts:
          - exp_labels:
              alertname: ModSecurityBlocking
              exported_namespace: test-application-dev
              ingress: test-application-ingress
              severity: alert-severity-tag
            exp_annotations:
              message: "Mod_Security is blocking ingress test-application-dev/test-application-ingress. Blocking http requests at rate of 0.37 per second."
              runbook_url: https://runbook.com/ingress-modsecurity-blocking
              dashboard_url: https://grafana.live.cloud-platform.service.justice.gov.uk/d/golden-signals/golden-signals?orgId=1&var-namespace=test-application-dev&var-service=test-application

  - interval: 1m
    input_series:
      - series: 'nginx_ingress_controller_requests{exported_namespace="test-application-dev", ingress="test-application-ingress", status="406"}'
        values: '0 20 38'

    name: ModSecurityBlocking alert not fired as request rate is equal to the threshold over the duration of the 1 minute time range window

    # this is here to help folks better understand the promql expression
    # at 2m the rate (increase per second) in the last minute: 0.3 ((38 - 20) / 60) which not greater than 0.33, assert nothing is returned
    promql_expr_test:
      - expr: avg(rate(nginx_ingress_controller_requests{exported_namespace="test-application-dev", ingress="test-application-ingress", status=~"406"}[1m]) > 0.33) by (ingress, exported_namespace)
        eval_time: 2m
        exp_samples: []

    alert_rule_test:
      # assert that the ModSecurityBlocking alert is NOT firing
      - eval_time: 2m
        alertname: ModSecurityBlocking
        exp_alerts: []
